{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Part 3: Algorithm Selection\n",
    "Now that we have finished appropriately feature engineering dataset, we are ready to begin testing out different algorithms to see which is the most performant. This notebook will include the following actions:\n",
    "\n",
    "- Importing the cleansed dataset from the \"/data/clean\" directory\n",
    "- Splitting the cleansed dataset in two for a training and validation dataset\n",
    "- Performing a feature scaling where required\n",
    "- Performing a GridSearch for ideal hyperparameter tuning\n",
    "- Testing out a number of different algorithms\n",
    "- Validating the results of each algorithm with model validation metrics / visualizations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the necessary Python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Importing the binary classification algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading in the cleaned dataset\n",
    "df_clean = pd.read_csv('../data/clean/new_data.csv')\n",
    "\n",
    "# Splitting the predictor value from the remainder of the dataset\n",
    "X = df_clean.drop(columns = ['Survived'])\n",
    "y = df_clean[['Survived']]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}